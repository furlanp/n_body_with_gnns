{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Gravity with Graph Neural Networks\n",
    "\n",
    "### by Petja Furlan and Lazar Đoković\n",
    "### Mentor: Lovro Šubelj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will present the code used in our Medium blog post *[Simulating Gravity with Graph Neural Networks](https://medium.com/@petjafurlan/simulating-gravity-with-graph-neural-networks-d3be57abf60f)*. The code was developed as part of the Machine learning with graphs course offered at the University of Ljubljana, Faculty of Computer and Information science.\n",
    "\n",
    "Let's start with a quick recap of the model we developed based on our findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraviNet\n",
    "\n",
    "*GraviNet* is an ensemble model used for learning rotational gravitational effects exhibited by planets orbiting stars. It combines (parellel) results from multiple heterogeneous models and aggregates them to get the final result. Each model is fed the node embeddings of the entire system at time *t* and outputs the velocities at time *t + 1*. We represent each system as a fully connected graph, where each node is an object and edges represent gravitational dependencies. \n",
    "\n",
    "The node embeddigs are characterized by planet feature vectors. These consist of:\n",
    "\n",
    "1. Mass\n",
    "2. Position\n",
    "3. Velocity\n",
    "\n",
    "where Position and Velocity can have either 2 or 3 components based on the simulation type (whether it is 2D or 3D). The simulation we will present will be a 2D simulation, where each body feature vector will be of the form $[m, x_1, x_2, v_1, v_2]^T$.\n",
    "\n",
    "The aggregation used to combine all of the outputs is a linear combination that is also learned.\n",
    "\n",
    "The choice of the number and type of models used within the GraviNet network is highly dependant on the type of simulation we would wish to learn. Therefore, the torch module is written in a modular fashion, allowing quick redefinitions of model types and counts via the arguments passed at module creation.\n",
    "\n",
    "The models we have decided to include in the GraviNet architecture are the following:\n",
    "\n",
    "1. InteractionGraphNetwork (IGN)\n",
    "2. Graph Isomorphism Network (GIN)\n",
    "3. Graph Convolutional Network (GCN)\n",
    "4. Multilayer Perceptron (MLP)\n",
    "\n",
    "where IGN is a second model we developed for learning rotational gravitational effects. More word on that soon.\n",
    "\n",
    "Our motivation for including these specific models is as follow:\n",
    "\n",
    "- We found that the IGN model was capable of learning only one rotational direction, which means that it can not simulate two bodies orbiting a star in different directions. Having a sum of two weighted IGNs enabled GraviNet to learn both rotations. Therefore, we recomend to have as many IGNs as there are distinct orbits.\n",
    "- GIN and GCN were added to capture interactions between systems with a greater number of moving objects. Their inclusions however, usually resulted in worse simulations so we recommend adding them only if IGNs and MLPs dont work.\n",
    "- MLPs were added to capture complex translational movements of entire system, i.e. a star system drifting in a certain direction.\n",
    "\n",
    "A scheme of the GraviNet architecture is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"diagrams\\GraviNet\\GraviNetImg.jpg\" alt=\"GraviNet Arch\"\twidth=\"752\" height=\"445\"/>\n",
    "  <figcaption>Fig. 1 - GraviNet Architecture.</figcaption>\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InteractionGraphNetwork\n",
    "\n",
    "A key component of our GraviNet model is the *InteractionGraphNetwork* (IGN) GNN. Here we will quickly present its architecture too.\n",
    "\n",
    "Our research found that regular graph neural networks like GCN, GAT and GIN are not able to learn rotation. For this reason, we spent a lot of time developing a model that would be powerful enough to learn this complex movement. Eventually, we developed a model inspired by the paper *[Interaction Networks for Learning about Objects,\n",
    "Relations and Physics](https://arxiv.org/pdf/1612.00222.pdf)*.\n",
    "\n",
    "InteractionGraphNetwork consists of:\n",
    "\n",
    "1. A four layer Linear encoder (MLP) module with hidden layer dimensions of length 150. Each layer except for the last is followed by a *Parametric Rectified Linear Unit* (PReLU) while the last layer is followed by a *Tanh* non-linearity. IGNs input is first passed to this encoder.\n",
    "2. A three layer GIN network with adjustable hidden layer size (GIN preformed the best in our empiric testing). The encoder output is passed to the GNN as input.\n",
    "3. A two layer Linear decoder (MLP) module with a single Tanh non-linearity in between the layers. The GNN output is concatenated with the original input to the IGN (with a skip-connection) and passed to the decoder.\n",
    "\n",
    "Interestingly, the key to learning rotation turned out to be the skip-connection. We theorize that this is due to the algorithmic alignment of this model to the problem at hand.\n",
    "\n",
    "A scheme of the InteractionGraphNetwork architecture is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"diagrams\\IN\\IN.jpg\" alt=\"IGN Arch\"\twidth=\"400\" height=\"500\"/>\n",
    "  <figcaption>Fig. 2 - IGN Architecture.</figcaption>\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraviNet speed and data shape\n",
    "\n",
    "One of the goals when designing our network was to keep it as GPU frendly as possible. Doing calculations on the graphics card makes the training process a lot quicker.\n",
    "\n",
    "This was made easier by the fact that certain pytorch_geometric models support message passing in *statics graphs*. This means that we can pass the network a input feature tensor of the form *[batch_size, num_nodes, input_dim]* and a single edge index and it will calculate the result for each batch seperately, using the same edge index for every *graph* in the batch. This makes traning faster since there is no need to iterate though the batch with a for-loop and the entire computation is done with tensor operations. \n",
    "\n",
    "For this reason, GraviNet accepts *either* a input tensor of shape *[batch_size, num_nodes, input_dim]* or *[num_nodes, input_dim]*. This makes training more effieicent. GraviNet then outputs either *[batch_size, num_nodes, d]* or *[num_nodes, d]* (*d* is 2 for 2D and 3 for 3D simulations) sized tensors that represent velocities in the next time step.\n",
    "\n",
    "You can find a list of pytorch_geometric networks that support static graphs *[here](https://pytorch-geometric.readthedocs.io/en/latest/notes/cheatsheet.html)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First we need to import all of the libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from drawer import PygApp\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from simulator import make_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.nn.models import GCN, GIN\n",
    "from simulator import FiveStars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "We also define a generic MLP class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A generic MLP class.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, act):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        layer_sizes : list\n",
    "            A list of layer dimensions. The MLP will have len(layers) - 1 layers.\n",
    "        hidden_dim : int\n",
    "            Hidden layer dimension\n",
    "        output_dim : int\n",
    "            Output layer dimension\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = [nn.Linear(input_dim, output_dim) for input_dim, output_dim in zip(layers, layers[1:])]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Tensor\n",
    "            Input feature tensor of size [batch_size x num_bodies x input_dim] or [num_bodies x input_dim]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            Output feature tensor of size [batch_size x num_bodies x output_dim] or [num_bodies x output_dim]\n",
    "        \"\"\"\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.act(layer(x))\n",
    "        out = self.layers[-1](x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the Encoder module described in the introduction. Be mindful of the Tanh placement when implementing this class yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class that represent a preprocessing MLP with 4 Linear layers\n",
    "    with PReLUs, followed by a tanh non-linearity.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        input_dim : int\n",
    "            Feature vector dimension\n",
    "        hidden_dim : int\n",
    "            Hidden layer dimension\n",
    "        output_dim : int\n",
    "            Output layer dimension\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Tensor\n",
    "            Input feature tensor of size [batch_size x num_bodies x input_dim] or [num_bodies x input_dim]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            Output feature tensor of size [batch_size x num_bodies x output_dim] or [num_bodies x output_dim]\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 2: return self.layers(x)\n",
    "        batch_size, num_bodies, input_dim = x.size()\n",
    "        x = x.view(-1, input_dim)\n",
    "        x = self.layers(x)\n",
    "        out = x.view(batch_size, num_bodies, self.output_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define the Decoder module, as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder class that represent a postprocessing MLP with 2 Linear layers\n",
    "    and a single tanh non-linearity placed after the first layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        input_dim : int\n",
    "            Feature vector dimension\n",
    "        hidden_dim : int\n",
    "            Hidden layer dimension\n",
    "        output_dim : int\n",
    "            Output layer dimension\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Tensor\n",
    "            Input feature tensor of size [batch_size x num_bodies x input_dim] or [num_bodies x input_dim]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            Output feature tensor of size [batch_size x num_bodies x output_dim] or [num_bodies x output_dim]\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 2: return self.layers(x)\n",
    "        batch_size, num_bodies, input_dim = x.size()\n",
    "        x = x.view(-1, input_dim)\n",
    "        x = self.layers(x)\n",
    "        out = x.view(batch_size, num_bodies, self.output_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The InteractionGraphNetwork is a GNN with the Encoder and Decoder modules previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionGraphNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    InteractionGraphNetwork class that combines pre and postprocessing MLPs with \n",
    "    GIN (a Graph Neural Network) to create a pytorch module capable of learning \n",
    "    rotation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        input_dim : int\n",
    "            Feature vector dimension\n",
    "        hidden_dim : int\n",
    "            Hidden layer dimension\n",
    "        output_dim : int\n",
    "            Output layer dimension\n",
    "        \"\"\"\n",
    "        super(InteractionGraphNetwork, self).__init__()\n",
    "        \n",
    "        self.relational_model = Encoder(input_dim, 150, hidden_dim)\n",
    "\n",
    "        self.gnn = GIN(hidden_dim, hidden_dim, 3, hidden_dim)\n",
    "\n",
    "        self.object_model = Decoder(input_dim + hidden_dim, 100, output_dim)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Tensor\n",
    "            Input feature tensor of size [batch_size x num_bodies x input_dim] or [num_bodies x input_dim]\n",
    "        edge_index : LongTensor\n",
    "            Graph connectivity in COO format with shape [2, num_edges]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            Output feature tensor of size [batch_size x num_bodies x output_dim] or [num_bodies x output_dim]\n",
    "        \"\"\"\n",
    "        # objects = torch.transpose(self.batch_norm(torch.transpose(objects, 1, 2)), 1, 2)\n",
    "        effects = self.relational_model(x)\n",
    "        effects = self.gnn(effects, edge_index)\n",
    "        out = self.object_model(torch.cat([x, effects], 1)) if len(x.shape) == 2 else self.object_model(torch.cat([x, effects], 2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the GraviNet module, which is a ensemble of various kinds of models, with the IGN at its heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraviNet(nn.Module):\n",
    "    \"\"\"\n",
    "    GraviNet class that combines multiple parallel InteractionGraphNetworks, GNNs and MLPs that\n",
    "    can learn more complex rotations and translations. It combines the results of all \n",
    "    the networks with a weighted sum of the outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, object_count, input_dim, hidden_dim, output_dim, int_net_count, gin_count, gcn_count, mlp_count):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        object_count : int\n",
    "            Number of bodies to simulate\n",
    "        input_dim : int\n",
    "            Feature vector dimension\n",
    "        hidden_dim : int\n",
    "            Hidden layer dimension\n",
    "        output_dim : int\n",
    "            Output layer dimension\n",
    "        int_net_count : int\n",
    "            Number of parallel InteractionGraphNetwork\n",
    "        gin_count : int\n",
    "            Number of parallel GINs\n",
    "        gcn_count : int\n",
    "            Number of parallel GCNs\n",
    "        mlp_count : int\n",
    "            Number of parallel MLPs\n",
    "        \"\"\"\n",
    "        super(GraviNet, self).__init__()\n",
    "        \n",
    "        self.ign = nn.ModuleList([InteractionGraphNetwork(input_dim, hidden_dim, output_dim) for _ in range(int_net_count)])\n",
    "\n",
    "        self.gin = nn.ModuleList([GIN(input_dim, hidden_dim, 2, output_dim) for _ in range(gin_count)])\n",
    "\n",
    "        self.gcn = nn.ModuleList([GCN(input_dim, hidden_dim, 2, output_dim) for _ in range(gcn_count)])\n",
    "\n",
    "        self.mlp = nn.ModuleList([MLP([input_dim, hidden_dim, hidden_dim, output_dim], nn.PReLU()) for _ in range(mlp_count)])\n",
    "\n",
    "        self.num_models = int_net_count + gin_count + gcn_count + mlp_count\n",
    "\n",
    "        self.weights = nn.ParameterList([nn.Parameter(torch.rand((object_count, 1))) for _ in range(self.num_models)])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Tensor\n",
    "            Input feature tensor of size [batch_size x num_bodies x input_dim] or [num_bodies x input_dim]\n",
    "        edge_index : LongTensor\n",
    "            Graph connectivity in COO format with shape [2, num_edges]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            Output feature tensor of size [batch_size x num_bodies x output_dim] or [num_bodies x output_dim]\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        models = self.ign + self.gin + self.gcn + self.mlp\n",
    "        for i in range(self.num_models):\n",
    "            model = models[i]\n",
    "            weight = self.weights[i]\n",
    "            emb = model(x) if isinstance(model, MLP) else model(x, edge_index)\n",
    "            outputs.append(emb*weight)\n",
    "        \n",
    "        out = torch.stack(outputs).sum(dim=0)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "For reproducibility purposes, we will set the random seeds in all of the modules we will use. We will also set the device to 'cuda', if a NVIDIA graphics card is available for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we define two functions that will help us visualise the model's traning loss and error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    A function to plot the training loss of a GNN.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    losses : list\n",
    "        A list of all of the losses during training\n",
    "    \"\"\"\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"GraviNet MSE Loss\", fontdict = {'size':20})\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_error(errors):\n",
    "    \"\"\"\n",
    "    A function to plot the training errors of a GNN.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    errors : list\n",
    "        A list of all of the errors during training\n",
    "    \"\"\"\n",
    "    plt.plot(errors)\n",
    "    plt.title(\"GraviNet Error\", fontdict = {'size':20})\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two functions are key to the successful traning of our model.\n",
    "\n",
    "First we will define the create_dataset function. This is a wrapper function that we can pass a description of a *system* and it will call our RK4 simulator (with step size *dt*) to create a dataset of size *timesteps*. It will create a tensor *dataset* of shape *[timesteps x num_bodies x body_features]*, send it to *device* and return it.\n",
    "Additionally, it will also add some gaussian noise to make overfitting less likely.\n",
    "\n",
    "As mentioned in the introduction, each body in 2D has features $[m, x_1, x_2, v_1, v_2]^T$.\n",
    "\n",
    "The second function we will define, is a batching function that will randomly sample time steps from *dataset* to create a batch of shape *[batch_size x num_bodies x body_features]*. Here, *batch_size* must be less than *timesteps*.\n",
    "\n",
    "It will return this tensor along with the ground truth. The ground truth is a tensor with the same dimensions. However, for each index corresponding to a time step in the batch, this tensor stores the speed of the succeeding time step from that particular index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(system, timesteps, dt, device):\n",
    "    \"\"\"\n",
    "    A function that uses our own RK4-based simulator to create a dataset on which a GNN can train.\n",
    "    It also adds some random noise to the dataset to reduce network overfitting.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    system : dict\n",
    "        A dictionary that represents the description of the simulated system\n",
    "    timesteps : int\n",
    "        Number of time steps to simulate\n",
    "    dt : float\n",
    "        The step size used in the RK4 method\n",
    "    device : str\n",
    "        The device to which to send the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : Tensor\n",
    "        Dataset tensor of size [timesteps x num_bodies x body_features]\n",
    "    \"\"\"\n",
    "    dataset = make_dataset(system, relative=False, dt=dt, no_vel=1, no_steps=timesteps)[:, :, :-2]\n",
    "\n",
    "    gauss_noise = np.random.normal(0, 0.001, dataset.shape)\n",
    "    dataset += gauss_noise\n",
    "\n",
    "    dataset = torch.FloatTensor(dataset).to(device)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_batch(dataset, timesteps, dimension, batch_size):\n",
    "    \"\"\"\n",
    "    A function that creates a batch of data randomly sampled from the dataset. It returns\n",
    "    the data and grount_truth seperately. The ground truth for time step 'i' that the \n",
    "    network wants to learn is the speed values from time step 'i + 1'.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dataset : Tensor\n",
    "        Dataset tensor of size [batch_size x num_bodies x body_features]\n",
    "    timesteps : int\n",
    "        Length of dataset in timesteps simulated\n",
    "    dimension : int\n",
    "        Dimension of simulation (2D or 3D)\n",
    "    batch_size : int\n",
    "        Size of the batch to create\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : Tensor\n",
    "        Data tensor of size [batch_size x num_bodies x body_features]\n",
    "    speed_labels : Tensor\n",
    "        Ground truth (label) tensor of size [batch_size x num_bodies x dimension]\n",
    "    \"\"\"\n",
    "    data_indecies  = random.sample(range(timesteps - 1), batch_size)\n",
    "    label_indecies = [i + 1 for i in data_indecies]\n",
    "    \n",
    "    data = dataset[data_indecies]\n",
    "    labels = dataset[label_indecies]\n",
    "    \n",
    "    speed_labels = labels[:, :, (dimension + 1):]\n",
    "    \n",
    "    data = Variable(data)\n",
    "    speed_labels = Variable(speed_labels)\n",
    "\n",
    "    return data, speed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a helper function that creates a fully connected edge index in COO format. For more information on the COO format, visit this *[link](https://pytorch.org/docs/stable/sparse.html)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_index(num_bodies, device):\n",
    "    \"\"\"\n",
    "    A function that creates a fully connected edge index (in COO format) used for GNN training.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    num_objects : int\n",
    "        Number of bodies in the simulation\n",
    "    device : str\n",
    "        The device to which to send the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edge_index : LongTensor\n",
    "        Graph connectivity in COO format with shape [2, num_edges]\n",
    "    \"\"\"\n",
    "    edge_index = [[], []]\n",
    "    for i in range(num_bodies):\n",
    "        for j in range(num_bodies):\n",
    "            if i != j:\n",
    "                edge_index[0].append(i)\n",
    "                edge_index[1].append(j)\n",
    "    edge_index = torch.LongTensor(edge_index).to(device)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also needed to be able to calculate the error that our model makes while simulating a gravitational system. Our goal was to be able to give the model a system state in a certain time step, and for it to continue the simulation from that time step onwards. This would require us to feed the model its own predictions after every step. This mechanism is called *rollout*. \n",
    "\n",
    "Testing the prediction of our model on single time steps would therefore not be a robust method to accurately gauge the model's accuracy. However, there is a big problem with rollout too. It is not parallelizable. That means that if we wanted to calculate the error our model was making at every epoch of training with a big rollout, the model would spend more time calculating the error than actually training. For this reason, we came up with a couple of optimizations:\n",
    "\n",
    "1. We randomly sampled a subset of time steps to do evaluation on. The randomness guarantees that, in the long run, each part of the orbit will be represented in the overall error.\n",
    "2. We limited the rollout length to a fixed size of 10. \n",
    "\n",
    "The fixed and relatively small size of the rollout meant that the evaluation would be quick. The length of 10 also assured that the model would be predicting states from values it had never seen before. This is because after every step, the model's inherent error nudges every body in the simulation into a position that it has most likely never seen before. From this, we saw that the rollout error was a good error estimate of the model, since it showed how the *drift* of the model changes over time.\n",
    "\n",
    "A visualization of *drift* is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"diagrams/drift/drift.jpg\" alt=\"Drift\"\twidth=\"650\" height=\"650\"/>\n",
    "  <figcaption>Fig. 3 - GraviNet drift. The black line is the ground truth, the blue lines are the model's predictions with rollout (of randomly sampled starting points) and the red arrows indicate the error the model made.</figcaption>\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model_with_rollout(model, edge_index, dataset, timesteps, test_size, rollout_len, dimension, dt):\n",
    "    \"\"\"\n",
    "    A function that calculated a GNNs error based on comparisons to ground truths in an rollout \n",
    "    enviroment. Rollout means that the model's outputs are fed back into the model to created the next\n",
    "    time step prediction. This function takes test_size examples, and for each example it calculates the error\n",
    "    for the next rollout_len time steps using rollout.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    model : torch.nn.Module\n",
    "        A pytorch NN model\n",
    "    edge_index : LongTensor\n",
    "        Graph connectivity in COO format with shape [2, num_edges]\n",
    "    dataset : Tensor\n",
    "        Dataset tensor of size [timesteps x num_bodies x body_features]\n",
    "    timesteps : int\n",
    "        Length of simulation in time steps\n",
    "    test_size : int\n",
    "        Number of examples used for testing (starting points for rollout)\n",
    "    rollout_len : int\n",
    "        How many rollout steps to take for each testing example\n",
    "    dimension : int\n",
    "        Dimension of simulation (2D or 3D)\n",
    "    dt : float\n",
    "        The step size used in the RK4 method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : float\n",
    "        Model error for sampled test set with rollout\n",
    "    \"\"\"\n",
    "    test_indecies = np.array(random.sample(range(timesteps - (rollout_len + 1)), test_size - (rollout_len + 1)))\n",
    "    positions = deepcopy(dataset[test_indecies])\n",
    "\n",
    "    error = 0\n",
    "    for _ in range(0, rollout_len):\n",
    "        test_indecies += 1\n",
    "        predicted = model(positions, edge_index)\n",
    "        positions[:, :, (dimension + 1):] = predicted\n",
    "        positions[:, :, 1:(dimension + 1)] += positions[:, :, (dimension + 1):] * dt\n",
    "        error += torch.sum(((positions - dataset[test_indecies]) ** 2) ** 0.5) \n",
    "\n",
    "    return error / (test_size * rollout_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally define our training function. It will employ the functions we defined above to train our model and it will find and return the best one.\n",
    "\n",
    "*train_model* will train the GraviNet network for *num_epochs*, creating a new batch with *get_batch* in every epoch. After the batch is passed to the model and the GNN returns a result, we will use *loss_fn* to calculate the loss and *test_model_with_rollout* to calculate the error. We will continously save the best model and backpropagate the results via the supplied *optimizer*. We will also return all of the losses and errors for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, edge_index, loss_fn, optimizer, num_epochs, dataset, timesteps, dimension, batch_size, dt):\n",
    "    \"\"\"\n",
    "    A function used for traning a GNN model with its edge index using a given loss function and optimizer. It\n",
    "    also stores and returnes the best model along with its losses and accuracies stored in lists during\n",
    "    the traning process.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    model : torch.nn.Module\n",
    "        A pytorch NN model\n",
    "    edge_index : LongTensor\n",
    "        Graph connectivity in COO format with shape [2, num_edges]\n",
    "    loss_fn : torch.nn.Module\n",
    "        Loss function used for traning\n",
    "    optimizer : torch.nn.Module\n",
    "        Optimizer used for traning\n",
    "    num_epoch : int\n",
    "        Number of epochs used for traning\n",
    "    dataset : Tensor\n",
    "        Dataset tensor of size [timesteps x num_bodies x body_features]\n",
    "    timesteps : int\n",
    "        Length of simulation in time steps\n",
    "    dimension : int\n",
    "        Dimension of simulation (2D or 3D)\n",
    "    batch_size : int\n",
    "        Size of batches used during traning (<= timesteps)\n",
    "    dt : float\n",
    "        The step size used in the RK4 method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_model : torch.nn.Module\n",
    "        The best model found during traning\n",
    "    losses : list\n",
    "        List of traning losses\n",
    "    accuracies : list\n",
    "        List of traning accuracies\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    errors = []\n",
    "    best_model = None\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        positions, speeds = get_batch(dataset, timesteps, dimension, batch_size)\n",
    "        predicted = model(positions, edge_index)\n",
    "        loss = loss_fn(predicted, speeds)\n",
    "\n",
    "        error = test_model_with_rollout(model, edge_index, dataset, timesteps, timesteps // 2, 10, dimension, dt)\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        errors.append(error.cpu())\n",
    "        print(f'epoch: {epoch}, loss: {losses[-1]}, accuracy: {error}')\n",
    "    \n",
    "    return best_model, losses, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "Now, we can finally prepare and train our GraviNet model. We will initialize a few parameters needed for our simualator. The step size in the RK4 method will be *dt = 0.1* and we will simulate bodies in 2 dimensions for *timesteps = 7000*. We will use one of ours predefined gravitational systems (Notebook) with 5 bodies orbiting a central star. This will be our traning dataset.\n",
    "\n",
    "We will create a GraviNet network with 6 IGNs and set *hidden_dim = 128*. Input and output dimensions are defined by the simulated system. MLPs are not needed because the central star is not drifting. Hence, 6 IGNs perform well for this task. \n",
    "\n",
    "For the optimizer we chose Adam, since it is very robust. For the loss function, we chose MSELoss.\n",
    "\n",
    "We trained the model for 500 epochs with a batch size equal to the number of time steps in our simulation, since we can afford it.\n",
    "\n",
    "After we created a fully connected edge index, we trained our model and saved the best one, along with its losses and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.06432455778121948, accuracy: 4.341667175292969\n",
      "epoch: 1, loss: 0.7696861028671265, accuracy: 13.969544410705566\n",
      "epoch: 2, loss: 0.018091367557644844, accuracy: 2.1195638179779053\n",
      "epoch: 3, loss: 0.08670774102210999, accuracy: 5.195662498474121\n",
      "epoch: 4, loss: 0.024520447477698326, accuracy: 2.8411452770233154\n",
      "epoch: 5, loss: 0.00852235034108162, accuracy: 1.5264413356781006\n",
      "epoch: 6, loss: 0.016278384253382683, accuracy: 2.2164981365203857\n",
      "epoch: 7, loss: 0.0028242163825780153, accuracy: 0.8323138356208801\n",
      "epoch: 8, loss: 0.010684657841920853, accuracy: 1.7901405096054077\n",
      "epoch: 9, loss: 0.0026217722333967686, accuracy: 0.88470858335495\n",
      "epoch: 10, loss: 0.004462467972189188, accuracy: 1.1383635997772217\n",
      "epoch: 11, loss: 0.004241454880684614, accuracy: 1.153051733970642\n",
      "epoch: 12, loss: 0.0036812988109886646, accuracy: 1.0785397291183472\n",
      "epoch: 13, loss: 0.004241745453327894, accuracy: 1.192521572113037\n",
      "epoch: 14, loss: 0.0022939995396882296, accuracy: 0.8645920753479004\n",
      "epoch: 15, loss: 0.00554363988339901, accuracy: 1.3882851600646973\n",
      "epoch: 16, loss: 0.005545940715819597, accuracy: 1.3765307664871216\n",
      "epoch: 17, loss: 0.00274818972684443, accuracy: 0.9907695055007935\n",
      "epoch: 18, loss: 0.0010519446805119514, accuracy: 0.6092221140861511\n",
      "epoch: 19, loss: 0.0035001076757907867, accuracy: 1.2355265617370605\n",
      "epoch: 20, loss: 0.0018268320709466934, accuracy: 0.7884519100189209\n",
      "epoch: 21, loss: 0.0018155805300921202, accuracy: 0.8063510060310364\n",
      "epoch: 22, loss: 0.0023278684820979834, accuracy: 0.985525906085968\n",
      "epoch: 23, loss: 0.0008930109324865043, accuracy: 0.5745617747306824\n",
      "epoch: 24, loss: 0.0010430082911625504, accuracy: 0.6482923626899719\n",
      "epoch: 25, loss: 0.0009445562027394772, accuracy: 0.631547749042511\n",
      "epoch: 26, loss: 0.0006532878032885492, accuracy: 0.5357176065444946\n",
      "epoch: 27, loss: 0.0013886896194890141, accuracy: 0.7909590601921082\n",
      "epoch: 28, loss: 0.0011064766440540552, accuracy: 0.7079744935035706\n",
      "epoch: 29, loss: 0.0009778760140761733, accuracy: 0.6517493724822998\n",
      "epoch: 30, loss: 0.0009274210897274315, accuracy: 0.6649178862571716\n",
      "epoch: 31, loss: 0.0007804819033481181, accuracy: 0.6260536909103394\n",
      "epoch: 32, loss: 0.0004920628271065652, accuracy: 0.5069798231124878\n",
      "epoch: 33, loss: 0.0008592234225943685, accuracy: 0.6758720874786377\n",
      "epoch: 34, loss: 0.0015786351868882775, accuracy: 0.9167769551277161\n",
      "epoch: 35, loss: 0.0015202084323391318, accuracy: 0.9709638357162476\n",
      "epoch: 36, loss: 0.00039996637497097254, accuracy: 0.4628588557243347\n",
      "epoch: 37, loss: 0.0008249321253970265, accuracy: 0.7073974609375\n",
      "epoch: 38, loss: 0.0006029511569067836, accuracy: 0.6073656678199768\n",
      "epoch: 39, loss: 0.0004176442453172058, accuracy: 0.5015919804573059\n",
      "epoch: 40, loss: 0.000794888474047184, accuracy: 0.6856479644775391\n",
      "epoch: 41, loss: 0.00089227658463642, accuracy: 0.7486903667449951\n",
      "epoch: 42, loss: 0.0004950090660713613, accuracy: 0.5451334118843079\n",
      "epoch: 43, loss: 0.0004686999600380659, accuracy: 0.533901035785675\n",
      "epoch: 44, loss: 0.00043891463428735733, accuracy: 0.5418875217437744\n",
      "epoch: 45, loss: 0.0003968137607444078, accuracy: 0.5119079947471619\n",
      "epoch: 46, loss: 0.0008971598581410944, accuracy: 0.7636941075325012\n",
      "epoch: 47, loss: 0.0004800779279321432, accuracy: 0.5966696739196777\n",
      "epoch: 48, loss: 0.0005539903067983687, accuracy: 0.6285460591316223\n",
      "epoch: 49, loss: 0.0005313470610417426, accuracy: 0.6235896944999695\n",
      "epoch: 50, loss: 0.0002568444760981947, accuracy: 0.41258102655410767\n",
      "epoch: 51, loss: 0.0005511741619557142, accuracy: 0.679409921169281\n",
      "epoch: 52, loss: 0.00028035807190462947, accuracy: 0.4425784647464752\n",
      "epoch: 53, loss: 0.0001786842185538262, accuracy: 0.36944344639778137\n",
      "epoch: 54, loss: 0.00022450006508734077, accuracy: 0.4016513228416443\n",
      "epoch: 55, loss: 0.00020345796656329185, accuracy: 0.394195556640625\n",
      "epoch: 56, loss: 0.0002424829435767606, accuracy: 0.4377293586730957\n",
      "epoch: 57, loss: 0.0002258192835142836, accuracy: 0.4123796224594116\n",
      "epoch: 58, loss: 0.0001444752124371007, accuracy: 0.33450525999069214\n",
      "epoch: 59, loss: 0.00025049643591046333, accuracy: 0.47168493270874023\n",
      "epoch: 60, loss: 0.00017652635870035738, accuracy: 0.369760662317276\n",
      "epoch: 61, loss: 0.00013855972792953253, accuracy: 0.34259694814682007\n",
      "epoch: 62, loss: 0.00015069416258484125, accuracy: 0.36538293957710266\n",
      "epoch: 63, loss: 0.0001227498723892495, accuracy: 0.3262149691581726\n",
      "epoch: 64, loss: 0.00011786022514570504, accuracy: 0.3136797547340393\n",
      "epoch: 65, loss: 0.0001161351683549583, accuracy: 0.3309069871902466\n",
      "epoch: 66, loss: 9.989341924665496e-05, accuracy: 0.30102139711380005\n",
      "epoch: 67, loss: 0.000125693462905474, accuracy: 0.3325956463813782\n",
      "epoch: 68, loss: 0.00010541751544224098, accuracy: 0.31518062949180603\n",
      "epoch: 69, loss: 0.0001011805870803073, accuracy: 0.3088042438030243\n",
      "epoch: 70, loss: 9.6843097708188e-05, accuracy: 0.29818740487098694\n",
      "epoch: 71, loss: 0.00013585823762696236, accuracy: 0.360349178314209\n",
      "epoch: 72, loss: 0.00010918088810285553, accuracy: 0.3459126353263855\n",
      "epoch: 73, loss: 0.00010200667747994885, accuracy: 0.3059450387954712\n",
      "epoch: 74, loss: 9.114187560044229e-05, accuracy: 0.29106974601745605\n",
      "epoch: 75, loss: 8.836833876557648e-05, accuracy: 0.31285780668258667\n",
      "epoch: 76, loss: 8.942222484620288e-05, accuracy: 0.30972176790237427\n",
      "epoch: 77, loss: 8.399730722885579e-05, accuracy: 0.29913944005966187\n",
      "epoch: 78, loss: 6.657517951680347e-05, accuracy: 0.27673521637916565\n",
      "epoch: 79, loss: 5.747462637373246e-05, accuracy: 0.2530827224254608\n",
      "epoch: 80, loss: 5.521444109035656e-05, accuracy: 0.24947257339954376\n",
      "epoch: 81, loss: 7.415661821141839e-05, accuracy: 0.2932891547679901\n",
      "epoch: 82, loss: 6.0848666180390865e-05, accuracy: 0.26262208819389343\n",
      "epoch: 83, loss: 5.674424392054789e-05, accuracy: 0.2539057731628418\n",
      "epoch: 84, loss: 5.5420117860194296e-05, accuracy: 0.2615063488483429\n",
      "epoch: 85, loss: 5.54223770450335e-05, accuracy: 0.2504884898662567\n",
      "epoch: 86, loss: 4.644120781449601e-05, accuracy: 0.2269619107246399\n",
      "epoch: 87, loss: 5.29743883816991e-05, accuracy: 0.25408464670181274\n",
      "epoch: 88, loss: 5.625604171655141e-05, accuracy: 0.2565462291240692\n",
      "epoch: 89, loss: 5.07319018652197e-05, accuracy: 0.2553752362728119\n",
      "epoch: 90, loss: 4.297656050766818e-05, accuracy: 0.23061026632785797\n",
      "epoch: 91, loss: 7.95576925156638e-05, accuracy: 0.33338215947151184\n",
      "epoch: 92, loss: 6.561878399224952e-05, accuracy: 0.2988894581794739\n",
      "epoch: 93, loss: 5.19354289281182e-05, accuracy: 0.26367083191871643\n",
      "epoch: 94, loss: 6.1755497881677e-05, accuracy: 0.29634931683540344\n",
      "epoch: 95, loss: 4.929453643853776e-05, accuracy: 0.2486603856086731\n",
      "epoch: 96, loss: 4.4103308027843013e-05, accuracy: 0.24094361066818237\n",
      "epoch: 97, loss: 5.525280357687734e-05, accuracy: 0.2743605375289917\n",
      "epoch: 98, loss: 2.996683724632021e-05, accuracy: 0.1947893649339676\n",
      "epoch: 99, loss: 5.1933497161371633e-05, accuracy: 0.2633458077907562\n",
      "epoch: 100, loss: 2.9691753297811374e-05, accuracy: 0.19678384065628052\n",
      "epoch: 101, loss: 4.231463390169665e-05, accuracy: 0.24034179747104645\n",
      "epoch: 102, loss: 3.1545838282909244e-05, accuracy: 0.20255522429943085\n",
      "epoch: 103, loss: 3.429067874094471e-05, accuracy: 0.21578241884708405\n",
      "epoch: 104, loss: 2.921358282037545e-05, accuracy: 0.19671383500099182\n",
      "epoch: 105, loss: 3.188761547789909e-05, accuracy: 0.20699381828308105\n",
      "epoch: 106, loss: 3.666799602797255e-05, accuracy: 0.2248271405696869\n",
      "epoch: 107, loss: 7.954570901347324e-05, accuracy: 0.37028953433036804\n",
      "epoch: 108, loss: 3.369141268194653e-05, accuracy: 0.215774267911911\n",
      "epoch: 109, loss: 4.492759762797505e-05, accuracy: 0.2636887729167938\n",
      "epoch: 110, loss: 5.450615208246745e-05, accuracy: 0.2949790060520172\n",
      "epoch: 111, loss: 2.440635762468446e-05, accuracy: 0.1797805279493332\n",
      "epoch: 112, loss: 4.91917016915977e-05, accuracy: 0.27395498752593994\n",
      "epoch: 113, loss: 3.287632353021763e-05, accuracy: 0.22435611486434937\n",
      "epoch: 114, loss: 2.751029205683153e-05, accuracy: 0.19873560965061188\n",
      "epoch: 115, loss: 4.316048580221832e-05, accuracy: 0.2584623396396637\n",
      "epoch: 116, loss: 1.9217324734199792e-05, accuracy: 0.15570497512817383\n",
      "epoch: 117, loss: 3.557730815373361e-05, accuracy: 0.23492056131362915\n",
      "epoch: 118, loss: 2.767665864666924e-05, accuracy: 0.1904679238796234\n",
      "epoch: 119, loss: 2.1336447389330715e-05, accuracy: 0.15728342533111572\n",
      "epoch: 120, loss: 3.2424672099296004e-05, accuracy: 0.2231709063053131\n",
      "epoch: 121, loss: 1.8783743144012988e-05, accuracy: 0.1486785113811493\n",
      "epoch: 122, loss: 2.5178367650369182e-05, accuracy: 0.18084780871868134\n",
      "epoch: 123, loss: 2.45957744482439e-05, accuracy: 0.18611817061901093\n",
      "epoch: 124, loss: 1.802187762223184e-05, accuracy: 0.15122565627098083\n",
      "epoch: 125, loss: 2.60798551607877e-05, accuracy: 0.18670706450939178\n",
      "epoch: 126, loss: 2.081886850646697e-05, accuracy: 0.16493266820907593\n",
      "epoch: 127, loss: 1.763805266818963e-05, accuracy: 0.14685402810573578\n",
      "epoch: 128, loss: 2.3385859094560146e-05, accuracy: 0.17332614958286285\n",
      "epoch: 129, loss: 1.6481781131005846e-05, accuracy: 0.13880766928195953\n",
      "epoch: 130, loss: 1.938802597578615e-05, accuracy: 0.15757906436920166\n",
      "epoch: 131, loss: 1.9730834537767805e-05, accuracy: 0.14882980287075043\n",
      "epoch: 132, loss: 1.5822392015252262e-05, accuracy: 0.1328572928905487\n",
      "epoch: 133, loss: 1.9142500605084933e-05, accuracy: 0.15703414380550385\n",
      "epoch: 134, loss: 1.732541568344459e-05, accuracy: 0.1372029185295105\n",
      "epoch: 135, loss: 1.5698758943472058e-05, accuracy: 0.12814296782016754\n",
      "epoch: 136, loss: 1.8402906789560802e-05, accuracy: 0.15590746700763702\n",
      "epoch: 137, loss: 1.552393769088667e-05, accuracy: 0.1266051083803177\n",
      "epoch: 138, loss: 1.6060927009675652e-05, accuracy: 0.12968094646930695\n",
      "epoch: 139, loss: 1.6985382899292745e-05, accuracy: 0.1425527185201645\n",
      "epoch: 140, loss: 1.4868563994241413e-05, accuracy: 0.12541931867599487\n",
      "epoch: 141, loss: 1.589882594998926e-05, accuracy: 0.12619441747665405\n",
      "epoch: 142, loss: 1.598813287273515e-05, accuracy: 0.1349470168352127\n",
      "epoch: 143, loss: 1.4507055311696604e-05, accuracy: 0.1231762021780014\n",
      "epoch: 144, loss: 1.5638024706277065e-05, accuracy: 0.12465627491474152\n",
      "epoch: 145, loss: 1.5145529687288217e-05, accuracy: 0.13101254403591156\n",
      "epoch: 146, loss: 1.4357435247802641e-05, accuracy: 0.12258961796760559\n",
      "epoch: 147, loss: 1.5187389180937316e-05, accuracy: 0.12288420647382736\n",
      "epoch: 148, loss: 1.4640055269410368e-05, accuracy: 0.1277870237827301\n",
      "epoch: 149, loss: 1.417453859176021e-05, accuracy: 0.12185411900281906\n",
      "epoch: 150, loss: 1.4808950254519004e-05, accuracy: 0.12087645381689072\n",
      "epoch: 151, loss: 1.4263643606682308e-05, accuracy: 0.1225169226527214\n",
      "epoch: 152, loss: 1.4022599316376727e-05, accuracy: 0.12119189649820328\n",
      "epoch: 153, loss: 1.4438781363423914e-05, accuracy: 0.11703991144895554\n",
      "epoch: 154, loss: 1.402088764734799e-05, accuracy: 0.1201305240392685\n",
      "epoch: 155, loss: 1.3827343536831904e-05, accuracy: 0.11845355480909348\n",
      "epoch: 156, loss: 1.4142177860776428e-05, accuracy: 0.11639275401830673\n",
      "epoch: 157, loss: 1.381063884764444e-05, accuracy: 0.11841504275798798\n",
      "epoch: 158, loss: 1.3663069694302976e-05, accuracy: 0.11664492636919022\n",
      "epoch: 159, loss: 1.3874018804926891e-05, accuracy: 0.11529078334569931\n",
      "epoch: 160, loss: 1.3667528946825769e-05, accuracy: 0.1179826557636261\n",
      "epoch: 161, loss: 1.3490876881405711e-05, accuracy: 0.11510877311229706\n",
      "epoch: 162, loss: 1.3658152965945192e-05, accuracy: 0.11412618309259415\n",
      "epoch: 163, loss: 1.3517417755792849e-05, accuracy: 0.11570693552494049\n",
      "epoch: 164, loss: 1.3357620446186047e-05, accuracy: 0.1132490485906601\n",
      "epoch: 165, loss: 1.344648171652807e-05, accuracy: 0.11251115798950195\n",
      "epoch: 166, loss: 1.3401637261267751e-05, accuracy: 0.1150803193449974\n",
      "epoch: 167, loss: 1.3229579053586349e-05, accuracy: 0.11183673143386841\n",
      "epoch: 168, loss: 1.327424070041161e-05, accuracy: 0.1106792464852333\n",
      "epoch: 169, loss: 1.3268799193610903e-05, accuracy: 0.11387813836336136\n",
      "epoch: 170, loss: 1.3140213923179545e-05, accuracy: 0.11139754205942154\n",
      "epoch: 171, loss: 1.3109206520312e-05, accuracy: 0.11053063720464706\n",
      "epoch: 172, loss: 1.3139559086994268e-05, accuracy: 0.11288285255432129\n",
      "epoch: 173, loss: 1.3049647350271698e-05, accuracy: 0.10984475165605545\n",
      "epoch: 174, loss: 1.2983577107661404e-05, accuracy: 0.11017456650733948\n",
      "epoch: 175, loss: 1.2999507816857658e-05, accuracy: 0.11099391430616379\n",
      "epoch: 176, loss: 1.296545633522328e-05, accuracy: 0.10821669548749924\n",
      "epoch: 177, loss: 1.288688144995831e-05, accuracy: 0.10974567383527756\n",
      "epoch: 178, loss: 1.2869843885709997e-05, accuracy: 0.10958517342805862\n",
      "epoch: 179, loss: 1.2867597433796618e-05, accuracy: 0.10800740867853165\n",
      "epoch: 180, loss: 1.2809198778995778e-05, accuracy: 0.10906293243169785\n",
      "epoch: 181, loss: 1.2762536243826617e-05, accuracy: 0.10878978669643402\n",
      "epoch: 182, loss: 1.2754482668242417e-05, accuracy: 0.10715246945619583\n",
      "epoch: 183, loss: 1.2732442883134354e-05, accuracy: 0.10826665908098221\n",
      "epoch: 184, loss: 1.2678719940595329e-05, accuracy: 0.10729002952575684\n",
      "epoch: 185, loss: 1.2649429663724732e-05, accuracy: 0.1068062111735344\n",
      "epoch: 186, loss: 1.263763533643214e-05, accuracy: 0.10690969973802567\n",
      "epoch: 187, loss: 1.2608339602593333e-05, accuracy: 0.10590377449989319\n",
      "epoch: 188, loss: 1.2565225006255787e-05, accuracy: 0.1065930500626564\n",
      "epoch: 189, loss: 1.2540440366137773e-05, accuracy: 0.10625697672367096\n",
      "epoch: 190, loss: 1.2525383681349922e-05, accuracy: 0.10541704297065735\n",
      "epoch: 191, loss: 1.2496204362832941e-05, accuracy: 0.10644470900297165\n",
      "epoch: 192, loss: 1.246101783181075e-05, accuracy: 0.10479161888360977\n",
      "epoch: 193, loss: 1.243666611117078e-05, accuracy: 0.10503579676151276\n",
      "epoch: 194, loss: 1.2419862287060823e-05, accuracy: 0.105140320956707\n",
      "epoch: 195, loss: 1.2393612450978253e-05, accuracy: 0.10425703227519989\n",
      "epoch: 196, loss: 1.2363113455649e-05, accuracy: 0.10446278750896454\n",
      "epoch: 197, loss: 1.2339024578977842e-05, accuracy: 0.10394730418920517\n",
      "epoch: 198, loss: 1.2321021131356247e-05, accuracy: 0.10361196845769882\n",
      "epoch: 199, loss: 1.2298771252972074e-05, accuracy: 0.10402578115463257\n",
      "epoch: 200, loss: 1.2271592822798993e-05, accuracy: 0.10284523665904999\n",
      "epoch: 201, loss: 1.2247210179339163e-05, accuracy: 0.10339468717575073\n",
      "epoch: 202, loss: 1.2227373190398794e-05, accuracy: 0.10326806455850601\n",
      "epoch: 203, loss: 1.2207716281409375e-05, accuracy: 0.102256640791893\n",
      "epoch: 204, loss: 1.2184109436930157e-05, accuracy: 0.10251126438379288\n",
      "epoch: 205, loss: 1.2160165169916581e-05, accuracy: 0.10241147875785828\n",
      "epoch: 206, loss: 1.2138974852859974e-05, accuracy: 0.1014191284775734\n",
      "epoch: 207, loss: 1.2120061001041904e-05, accuracy: 0.10227428376674652\n",
      "epoch: 208, loss: 1.2100094863853883e-05, accuracy: 0.10161161422729492\n",
      "epoch: 209, loss: 1.2078106010449119e-05, accuracy: 0.10155375301837921\n",
      "epoch: 210, loss: 1.2056362720613834e-05, accuracy: 0.10113095492124557\n",
      "epoch: 211, loss: 1.2036211956001353e-05, accuracy: 0.10129041224718094\n",
      "epoch: 212, loss: 1.201743543788325e-05, accuracy: 0.10088959336280823\n",
      "epoch: 213, loss: 1.1998143236269243e-05, accuracy: 0.10034366697072983\n",
      "epoch: 214, loss: 1.197798155772034e-05, accuracy: 0.1001904159784317\n",
      "epoch: 215, loss: 1.1957707101828419e-05, accuracy: 0.09984622150659561\n",
      "epoch: 216, loss: 1.1938263014599215e-05, accuracy: 0.10026904195547104\n",
      "epoch: 217, loss: 1.1919964890694246e-05, accuracy: 0.10002969950437546\n",
      "epoch: 218, loss: 1.1901923244295176e-05, accuracy: 0.09951876103878021\n",
      "epoch: 219, loss: 1.1883640581800137e-05, accuracy: 0.09963575750589371\n",
      "epoch: 220, loss: 1.186495956062572e-05, accuracy: 0.09961356222629547\n",
      "epoch: 221, loss: 1.184640404972015e-05, accuracy: 0.09941897541284561\n",
      "epoch: 222, loss: 1.1828402421087958e-05, accuracy: 0.09928707033395767\n",
      "epoch: 223, loss: 1.1810912837972865e-05, accuracy: 0.09897462278604507\n",
      "epoch: 224, loss: 1.1793784324254375e-05, accuracy: 0.0992247611284256\n",
      "epoch: 225, loss: 1.1776617611758411e-05, accuracy: 0.09859480708837509\n",
      "epoch: 226, loss: 1.1759378139686305e-05, accuracy: 0.09841323643922806\n",
      "epoch: 227, loss: 1.1742131391656585e-05, accuracy: 0.09832073003053665\n",
      "epoch: 228, loss: 1.1725050171662588e-05, accuracy: 0.0981505885720253\n",
      "epoch: 229, loss: 1.1708300007740036e-05, accuracy: 0.09818731993436813\n",
      "epoch: 230, loss: 1.169183997262735e-05, accuracy: 0.09778382629156113\n",
      "epoch: 231, loss: 1.1675647328956984e-05, accuracy: 0.097721166908741\n",
      "epoch: 232, loss: 1.16595992949442e-05, accuracy: 0.09783871471881866\n",
      "epoch: 233, loss: 1.1643622201518156e-05, accuracy: 0.0973462164402008\n",
      "epoch: 234, loss: 1.1627716048678849e-05, accuracy: 0.09726237505674362\n",
      "epoch: 235, loss: 1.161185537057463e-05, accuracy: 0.09740632772445679\n",
      "epoch: 236, loss: 1.1596100193855818e-05, accuracy: 0.09707888215780258\n",
      "epoch: 237, loss: 1.1580466889427043e-05, accuracy: 0.09734509885311127\n",
      "epoch: 238, loss: 1.1564973647182342e-05, accuracy: 0.09706282615661621\n",
      "epoch: 239, loss: 1.1549642294994555e-05, accuracy: 0.09679722040891647\n",
      "epoch: 240, loss: 1.1534453733474948e-05, accuracy: 0.09701026231050491\n",
      "epoch: 241, loss: 1.1519411600602325e-05, accuracy: 0.09650469571352005\n",
      "epoch: 242, loss: 1.1504500434966758e-05, accuracy: 0.09674734622240067\n",
      "epoch: 243, loss: 1.1489695680211298e-05, accuracy: 0.09618443995714188\n",
      "epoch: 244, loss: 1.1474982784420718e-05, accuracy: 0.09634847193956375\n",
      "epoch: 245, loss: 1.1460358109616209e-05, accuracy: 0.0963820070028305\n",
      "epoch: 246, loss: 1.1445837117207702e-05, accuracy: 0.09636487811803818\n",
      "epoch: 247, loss: 1.1431425264163408e-05, accuracy: 0.09629226475954056\n",
      "epoch: 248, loss: 1.141713892138796e-05, accuracy: 0.09627638757228851\n",
      "epoch: 249, loss: 1.1402987183828373e-05, accuracy: 0.09570253640413284\n",
      "epoch: 250, loss: 1.138900734076742e-05, accuracy: 0.09609988331794739\n",
      "epoch: 251, loss: 1.1375277608749457e-05, accuracy: 0.09593253582715988\n",
      "epoch: 252, loss: 1.1361883480276447e-05, accuracy: 0.09562716633081436\n",
      "epoch: 253, loss: 1.1349005035299342e-05, accuracy: 0.09572545439004898\n",
      "epoch: 254, loss: 1.1337222531437874e-05, accuracy: 0.09562110155820847\n",
      "epoch: 255, loss: 1.1327556421747431e-05, accuracy: 0.09538307785987854\n",
      "epoch: 256, loss: 1.1321881174808368e-05, accuracy: 0.09557420760393143\n",
      "epoch: 257, loss: 1.1323860235279426e-05, accuracy: 0.09533374011516571\n",
      "epoch: 258, loss: 1.1340310265950393e-05, accuracy: 0.09685276448726654\n",
      "epoch: 259, loss: 1.1386166079319082e-05, accuracy: 0.0963519960641861\n",
      "epoch: 260, loss: 1.1490735232655425e-05, accuracy: 0.09953663498163223\n",
      "epoch: 261, loss: 1.1716990229615476e-05, accuracy: 0.10176672786474228\n",
      "epoch: 262, loss: 1.2198444892419502e-05, accuracy: 0.11017170548439026\n",
      "epoch: 263, loss: 1.3228658644948155e-05, accuracy: 0.12322717905044556\n",
      "epoch: 264, loss: 1.545586928841658e-05, accuracy: 0.14704470336437225\n",
      "epoch: 265, loss: 2.0330546249169856e-05, accuracy: 0.1870182901620865\n",
      "epoch: 266, loss: 3.105077121290378e-05, accuracy: 0.2501915693283081\n",
      "epoch: 267, loss: 5.450308526633307e-05, accuracy: 0.3458103835582733\n",
      "epoch: 268, loss: 0.00010385913628851995, accuracy: 0.48988014459609985\n",
      "epoch: 269, loss: 0.00019820719899144024, accuracy: 0.6784887909889221\n",
      "epoch: 270, loss: 0.0004487103142309934, accuracy: 0.9431217908859253\n",
      "epoch: 271, loss: 0.0009366619633510709, accuracy: 1.3365072011947632\n",
      "epoch: 272, loss: 0.0010798880830407143, accuracy: 1.5598492622375488\n",
      "epoch: 273, loss: 0.0009426922188140452, accuracy: 1.611551284790039\n",
      "epoch: 274, loss: 0.0002760434290394187, accuracy: 0.8488517999649048\n",
      "epoch: 275, loss: 5.9940673963865265e-05, accuracy: 0.3587057590484619\n",
      "epoch: 276, loss: 0.0005087819881737232, accuracy: 1.104066014289856\n",
      "epoch: 277, loss: 0.000405060505727306, accuracy: 1.040859580039978\n",
      "epoch: 278, loss: 0.00020499610400293022, accuracy: 0.7138851284980774\n",
      "epoch: 279, loss: 0.0003181910142302513, accuracy: 1.003995418548584\n",
      "epoch: 280, loss: 9.058688738150522e-05, accuracy: 0.517652690410614\n",
      "epoch: 281, loss: 5.414705447037704e-05, accuracy: 0.37435173988342285\n",
      "epoch: 282, loss: 4.61841445940081e-05, accuracy: 0.2953294813632965\n",
      "epoch: 283, loss: 1.7302481865044683e-05, accuracy: 0.14539773762226105\n",
      "epoch: 284, loss: 7.050584099488333e-05, accuracy: 0.42330828309059143\n",
      "epoch: 285, loss: 0.0001415976439602673, accuracy: 0.6052030920982361\n",
      "epoch: 286, loss: 0.00024028251937124878, accuracy: 0.76010662317276\n",
      "epoch: 287, loss: 0.0005612025852315128, accuracy: 1.310289978981018\n",
      "epoch: 288, loss: 0.00019909525872208178, accuracy: 0.6672629714012146\n",
      "epoch: 289, loss: 0.00011180025467183441, accuracy: 0.5068126916885376\n",
      "epoch: 290, loss: 0.00043131757411174476, accuracy: 1.0741227865219116\n",
      "epoch: 291, loss: 0.00075122294947505, accuracy: 1.3186924457550049\n",
      "epoch: 292, loss: 0.000324408698361367, accuracy: 0.9117574691772461\n",
      "epoch: 293, loss: 0.00018371989426668733, accuracy: 0.6794348359107971\n",
      "epoch: 294, loss: 0.000536121369805187, accuracy: 1.1109046936035156\n",
      "epoch: 295, loss: 0.0003410754434298724, accuracy: 0.9009248614311218\n",
      "epoch: 296, loss: 6.310523895081133e-05, accuracy: 0.32666492462158203\n",
      "epoch: 297, loss: 0.00026250790688209236, accuracy: 0.8009605407714844\n",
      "epoch: 298, loss: 0.00025334631209261715, accuracy: 0.7313295602798462\n",
      "epoch: 299, loss: 0.00013012696581427008, accuracy: 0.5356138944625854\n",
      "epoch: 300, loss: 3.443829336902127e-05, accuracy: 0.2585851848125458\n",
      "epoch: 301, loss: 0.0007939942297525704, accuracy: 1.2536622285842896\n",
      "epoch: 302, loss: 0.001472813542932272, accuracy: 1.6869697570800781\n",
      "epoch: 303, loss: 0.00022323057055473328, accuracy: 0.6770929098129272\n",
      "epoch: 304, loss: 0.0004905405221506953, accuracy: 0.9765278100967407\n",
      "epoch: 305, loss: 0.0007549884612672031, accuracy: 1.2317396402359009\n",
      "epoch: 306, loss: 4.3387826735852286e-05, accuracy: 0.2704031765460968\n",
      "epoch: 307, loss: 0.000678813667036593, accuracy: 1.3011422157287598\n",
      "epoch: 308, loss: 0.00019533568411134183, accuracy: 0.6569420099258423\n",
      "epoch: 309, loss: 0.0003348167520016432, accuracy: 0.9800664186477661\n",
      "epoch: 310, loss: 0.00031213846523314714, accuracy: 0.9207993745803833\n",
      "epoch: 311, loss: 9.137541201198474e-05, accuracy: 0.4458784759044647\n",
      "epoch: 312, loss: 0.00023468962172046304, accuracy: 0.7967349886894226\n",
      "epoch: 313, loss: 9.560957551002502e-05, accuracy: 0.4923735558986664\n",
      "epoch: 314, loss: 0.00020944919378962368, accuracy: 0.7287131547927856\n",
      "epoch: 315, loss: 5.5652337323408574e-05, accuracy: 0.3300374150276184\n",
      "epoch: 316, loss: 0.00034810538636520505, accuracy: 0.9288129806518555\n",
      "epoch: 317, loss: 0.0003757108352147043, accuracy: 1.0039763450622559\n",
      "epoch: 318, loss: 0.0001345081109320745, accuracy: 0.6138145327568054\n",
      "epoch: 319, loss: 0.00015468199853785336, accuracy: 0.6656509041786194\n",
      "epoch: 320, loss: 0.0003011164953932166, accuracy: 0.921600341796875\n",
      "epoch: 321, loss: 0.00017897767247632146, accuracy: 0.7111782431602478\n",
      "epoch: 322, loss: 0.00021603007917292416, accuracy: 0.6760632991790771\n",
      "epoch: 323, loss: 2.412628055026289e-05, accuracy: 0.19363051652908325\n",
      "epoch: 324, loss: 0.00010243016004096717, accuracy: 0.5030450820922852\n",
      "epoch: 325, loss: 7.460259075742215e-05, accuracy: 0.36385008692741394\n",
      "epoch: 326, loss: 0.00011706732038874179, accuracy: 0.6093785762786865\n",
      "epoch: 327, loss: 1.8672755686566234e-05, accuracy: 0.17277663946151733\n",
      "epoch: 328, loss: 8.280065230792388e-05, accuracy: 0.4873276650905609\n",
      "epoch: 329, loss: 6.20322534814477e-05, accuracy: 0.41853219270706177\n",
      "epoch: 330, loss: 3.593176370486617e-05, accuracy: 0.2926848232746124\n",
      "epoch: 331, loss: 9.319416858488694e-05, accuracy: 0.46354350447654724\n",
      "epoch: 332, loss: 2.0846884581260383e-05, accuracy: 0.1934976577758789\n",
      "epoch: 333, loss: 7.28509112377651e-05, accuracy: 0.4782150089740753\n",
      "epoch: 334, loss: 3.815639502136037e-05, accuracy: 0.2981187701225281\n",
      "epoch: 335, loss: 3.629027560236864e-05, accuracy: 0.2831718921661377\n",
      "epoch: 336, loss: 4.4977412471780553e-05, accuracy: 0.3617245852947235\n",
      "epoch: 337, loss: 1.6520320059498772e-05, accuracy: 0.16620483994483948\n",
      "epoch: 338, loss: 5.114293162478134e-05, accuracy: 0.3577272891998291\n",
      "epoch: 339, loss: 3.160063715768047e-05, accuracy: 0.26188769936561584\n",
      "epoch: 340, loss: 4.103179890080355e-05, accuracy: 0.29311689734458923\n",
      "epoch: 341, loss: 1.9519804482115433e-05, accuracy: 0.19287575781345367\n",
      "epoch: 342, loss: 3.0471164791379124e-05, accuracy: 0.2430902123451233\n",
      "epoch: 343, loss: 2.507150020392146e-05, accuracy: 0.213981032371521\n",
      "epoch: 344, loss: 2.1478597773239017e-05, accuracy: 0.20458979904651642\n",
      "epoch: 345, loss: 1.8405622540740296e-05, accuracy: 0.18272393941879272\n",
      "epoch: 346, loss: 1.591516593180131e-05, accuracy: 0.15129989385604858\n",
      "epoch: 347, loss: 1.8409540643915534e-05, accuracy: 0.17672178149223328\n",
      "epoch: 348, loss: 1.3446450793708209e-05, accuracy: 0.13154679536819458\n",
      "epoch: 349, loss: 1.5085135601111688e-05, accuracy: 0.15596221387386322\n",
      "epoch: 350, loss: 1.3931490684626624e-05, accuracy: 0.13768339157104492\n",
      "epoch: 351, loss: 1.920264730870258e-05, accuracy: 0.18144448101520538\n",
      "epoch: 352, loss: 2.46468680416001e-05, accuracy: 0.22580039501190186\n",
      "epoch: 353, loss: 1.821792648115661e-05, accuracy: 0.1749214082956314\n",
      "epoch: 354, loss: 1.2764432540279813e-05, accuracy: 0.12497751414775848\n",
      "epoch: 355, loss: 1.6172669347724877e-05, accuracy: 0.15728607773780823\n",
      "epoch: 356, loss: 1.9268276446382515e-05, accuracy: 0.18003633618354797\n",
      "epoch: 357, loss: 1.407796298735775e-05, accuracy: 0.13689714670181274\n",
      "epoch: 358, loss: 1.171116946352413e-05, accuracy: 0.12030032277107239\n",
      "epoch: 359, loss: 1.5016671568446327e-05, accuracy: 0.14561530947685242\n",
      "epoch: 360, loss: 1.3994617802381981e-05, accuracy: 0.1431991010904312\n",
      "epoch: 361, loss: 1.179930677608354e-05, accuracy: 0.12093581259250641\n",
      "epoch: 362, loss: 1.2893906387034804e-05, accuracy: 0.12438368797302246\n",
      "epoch: 363, loss: 1.4110398296907078e-05, accuracy: 0.14628945291042328\n",
      "epoch: 364, loss: 1.1682779586408287e-05, accuracy: 0.11443178355693817\n",
      "epoch: 365, loss: 1.1680711395456456e-05, accuracy: 0.11491214483976364\n",
      "epoch: 366, loss: 1.3036133168498054e-05, accuracy: 0.13322632014751434\n",
      "epoch: 367, loss: 1.1889437701029237e-05, accuracy: 0.11557400226593018\n",
      "epoch: 368, loss: 1.1187364179932047e-05, accuracy: 0.1132970005273819\n",
      "epoch: 369, loss: 2.0619547285605222e-05, accuracy: 0.20356079936027527\n",
      "epoch: 370, loss: 3.7952588172629476e-05, accuracy: 0.30175450444221497\n",
      "epoch: 371, loss: 1.8239376004203223e-05, accuracy: 0.18196342885494232\n",
      "epoch: 372, loss: 1.4130706404102966e-05, accuracy: 0.14445747435092926\n",
      "epoch: 373, loss: 2.8891412512166426e-05, accuracy: 0.2581632137298584\n",
      "epoch: 374, loss: 1.6788393622846343e-05, accuracy: 0.16872523725032806\n",
      "epoch: 375, loss: 1.2849754057242535e-05, accuracy: 0.1278233379125595\n",
      "epoch: 376, loss: 2.3119386241887696e-05, accuracy: 0.22292445600032806\n",
      "epoch: 377, loss: 1.389858061884297e-05, accuracy: 0.14319662749767303\n",
      "epoch: 378, loss: 1.291502394451527e-05, accuracy: 0.13193577527999878\n",
      "epoch: 379, loss: 1.9234030332881957e-05, accuracy: 0.19379906356334686\n",
      "epoch: 380, loss: 1.1697374247887637e-05, accuracy: 0.12041319906711578\n",
      "epoch: 381, loss: 1.3546335139835719e-05, accuracy: 0.14118017256259918\n",
      "epoch: 382, loss: 1.6283427612506784e-05, accuracy: 0.1670464128255844\n",
      "epoch: 383, loss: 1.0539718459767755e-05, accuracy: 0.10709439218044281\n",
      "epoch: 384, loss: 1.3858257261745166e-05, accuracy: 0.14636953175067902\n",
      "epoch: 385, loss: 1.3598207260656636e-05, accuracy: 0.14104579389095306\n",
      "epoch: 386, loss: 1.036965932144085e-05, accuracy: 0.10192985832691193\n",
      "epoch: 387, loss: 1.3711241990677081e-05, accuracy: 0.1448504477739334\n",
      "epoch: 388, loss: 1.164756940852385e-05, accuracy: 0.11716172099113464\n",
      "epoch: 389, loss: 1.0844507414731197e-05, accuracy: 0.10746833682060242\n",
      "epoch: 390, loss: 1.28741030493984e-05, accuracy: 0.13590291142463684\n",
      "epoch: 391, loss: 1.0472527719684877e-05, accuracy: 0.10306131094694138\n",
      "epoch: 392, loss: 1.1250160241615959e-05, accuracy: 0.11334241181612015\n",
      "epoch: 393, loss: 1.1777642612287309e-05, accuracy: 0.1230652779340744\n",
      "epoch: 394, loss: 1.0118431418959517e-05, accuracy: 0.10036454349756241\n",
      "epoch: 395, loss: 1.138957122748252e-05, accuracy: 0.11496232450008392\n",
      "epoch: 396, loss: 1.0801373719004914e-05, accuracy: 0.11024591326713562\n",
      "epoch: 397, loss: 1.018385955831036e-05, accuracy: 0.10141444206237793\n",
      "epoch: 398, loss: 1.1126385288662277e-05, accuracy: 0.11234845221042633\n",
      "epoch: 399, loss: 1.0167402251681779e-05, accuracy: 0.10086004436016083\n",
      "\n",
      "Best loss: 1.0118431418959517e-05, best accuracy: 0.09533374011516571\n"
     ]
    }
   ],
   "source": [
    "dt = 0.1 \n",
    "dimension = 2\n",
    "timesteps = 7000\n",
    "system = FiveStars()\n",
    "dataset = create_dataset(system, timesteps, dt, device)\n",
    "num_objects = dataset.shape[1]\n",
    "input_dim = dataset.shape[2]\n",
    "hidden_dim = 128\n",
    "\n",
    "model = GraviNet(num_objects, input_dim, hidden_dim, dimension, 6, 0, 0, 0).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = timesteps - 1\n",
    "\n",
    "edge_index = create_edge_index(num_objects, device)\n",
    "\n",
    "model, losses, errors = train_model(model, edge_index, loss_fn, optimizer, num_epochs, dataset, timesteps, dimension, batch_size, dt)\n",
    "\n",
    "print(f'\\nBest loss: {min(losses)}, best accuracy: {min(errors)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "If we plot out the loss our model had during training, we see that the loss quickly falls to a low values, however, it is necessary to continue training until we reach a satisfactory error value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the error our model made, we can see how fast our model learns to simulate the given system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, this snippet of code runs a pygame simulation that draws out the movement of the simulated bodies that our model predicts with rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "objects = dataset[0].unsqueeze(0)\n",
    "@torch.no_grad()\n",
    "def update_func():\n",
    "    global objects\n",
    "    predicted = model(objects, edge_index)\n",
    "\n",
    "    objects[0, :, (dimension + 1):] = predicted\n",
    "    objects[0, :, 1:(dimension + 1)] += objects[0, :, (dimension + 1):] * dt\n",
    "    draw = []\n",
    "    for i in range(objects.shape[1]):\n",
    "        curr = list(objects[0, i, 1:(dimension + 1)]) + [0] if dimension == 2 else list(objects[0, i, 1:(dimension + 1)])\n",
    "        draw.append(curr)\n",
    "    return draw\n",
    "\n",
    "app = PygApp(update_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, closing the pygame window doesn't work and forcefully closing it causes the kernel to crash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Trying to solve the N-body problem with Graph Neural Networks proved to be both a fascinating and exceptionally challenging task. Our exploration highlighted the need for further research to uncover more effective models, since learning numerical integrators is no easy feat for regular Graph Neural Networks.\n",
    "\n",
    "We hope you enjoyed reading our Notebook on this topic and we hope that you found it engaging. In it, we showcased two GNN architectures: IGN and GraviNet. While IGN demonstrated its ability to model simple rotations, it fell short on more complex tasks. We also presented GraviNet and its capability to handle slightly more intricate systems. It is, however, important to emphasize that GraviNet is a long ways away from being useful in the real world. Tho it has shown that it has potential. This makes us believe that Graph Neural Networks will become even more widespread in physics in the coming years as this is only one of the many possible real-world applications in which GNNs can be used.\n",
    "\n",
    "If you are interested in additional information regarding the GraviNet model, we invite you to read our Medium *[post](https://medium.com/@petjafurlan/simulating-gravity-with-graph-neural-networks-d3be57abf60f)*. We appreciate your time and interest. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
